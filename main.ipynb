{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Seminário de Introdução a Imagens Médicas - Inteligência artificial aplica a imagens médicas**\n",
    "\n",
    "### *Breast Cancer Detection using Machine Learning Techniques*\n",
    "\n",
    "**Alunos:** _Caio Fernandes Lott Primola_     - 20193001742<br>\n",
    "_Henrique Rodrigues Lima_         - 20193009473<br>\n",
    "_João Pedro de Almeida Campos_         - 20203003792<br>\n",
    "_Victor Cunha Freitas Lara_         - 20193015695<br>\n",
    "\n",
    "Este trabalho consiste na simulação, analise e comparação entre uma rede neural densa e uma rede neural convolucional básica.\n",
    "\n",
    "As técnicas utilizadas foram:<br>\n",
    "    - Redes neurais convolucionais (CNN);<br>\n",
    "    - Rede Neural Densa (NN);<br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalar as bibliotecas necessárias, utilize a célula abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (4.8.1.78)\n",
      "Requirement already satisfied: numpy in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (1.25.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (2.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (0.24.0)\n",
      "Collecting scikeras (from -r requirements.txt (line 6))\n",
      "  Using cached scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow->-r requirements.txt (line 3)) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.31.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->-r requirements.txt (line 5)) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->-r requirements.txt (line 5)) (10.1.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->-r requirements.txt (line 5)) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->-r requirements.txt (line 5)) (2024.8.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->-r requirements.txt (line 5)) (0.4)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 4))\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (13.8.0)\n",
      "Requirement already satisfied: namex in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jp\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow->-r requirements.txt (line 3)) (2.1.5)\n",
      "Using cached scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Downloading scikit_learn-1.5.1-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.0 MB 991.0 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.3/11.0 MB 2.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/11.0 MB 3.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/11.0 MB 3.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.9/11.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 3.9 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.4/11.0 MB 4.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 4.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/11.0 MB 4.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.0/11.0 MB 4.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.3/11.0 MB 4.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.5/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.7/11.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.3/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.6/11.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.8/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.1/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.3/11.0 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.0/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.4/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.6/11.0 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.9/11.0 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.0/11.0 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.7/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.9/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.6/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.1/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.3/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.9/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.3/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.6/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn, scikeras\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "Successfully installed scikeras-0.13.0 scikit-learn-1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\JP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~klearn'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialização e carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  precision_score, confusion_matrix,  recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"histology_slides\"  \n",
    "regex_label = r\"[A-Z]+_([A-Z])_[A-Z]+-\\d{2}-[A-Z\\d]+-(\\d+)-\\d+\\.png\"\n",
    "magnification = \"200X\" #diretorio da magnificação desejada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path, magnification, img_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    num_files = 0\n",
    "\n",
    "    # Percorrer o diretório de imagens\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        if os.path.basename(root) == magnification: \n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    \n",
    "                    if img is None:\n",
    "                        print(f\"Erro ao carregar imagem: {file}\")\n",
    "                        continue\n",
    "                    \n",
    "                    img = cv2.resize(img, img_size)\n",
    "                    X.append(img)\n",
    "\n",
    "                    match_obj = re.search(regex_label, file)\n",
    "                    if match_obj:\n",
    "                        label = match_obj.group(1)\n",
    "                        y.append(True if label == \"M\" else False)\n",
    "                    else:\n",
    "                        print(f\"Erro ao extrair rótulo da imagem: {file}\")\n",
    "                    \n",
    "                    num_files += 1\n",
    "\n",
    "    print(f\"Total de imagens processadas: {num_files}\")\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens processadas: 941\n"
     ]
    }
   ],
   "source": [
    "img_size = (700, 460)\n",
    "X, y = load_data(dataset_path, magnification, img_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 589, False: 352})\n"
     ]
    }
   ],
   "source": [
    "count = Counter(y)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessemamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "selector = SelectKBest(f_classif, k=500) \n",
    "X_new = selector.fit_transform(X_flat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rfe = RFE(estimator=lr, n_features_to_select=100, step=50)\n",
    "X_rfe = rfe.fit_transform(X_new, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação entre dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: (752, 100), Teste: (189, 100)\n"
     ]
    }
   ],
   "source": [
    "X_rfe, y = shuffle(X_rfe, y)\n",
    "\n",
    "# Dividindo os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Treinamento: {X_train.shape}, Teste: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "### Redes Neural Densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_nn(input_shape):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(0.3),  # Dropout para evitar overfitting\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Saída binária (maligno ou benigno)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Básico de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_basic_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def avaliacoes(model, X_train, y_train, X_test, y_test):\n",
    "    # Configurar callback para ajuste da taxa de aprendizado\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.00001)\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32, callbacks=[lr_scheduler])\n",
    "\n",
    "    # Avaliação do modelo\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Matriz de Confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Métricas de Desempenho\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "    print(f\"Precisão: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # Repartição dos dados para validação cruzada\n",
    "    X, y = shuffle(X_train, y_train, random_state=42)\n",
    "    \n",
    "    # Utilização de KerasClassifier para integração com scikit-learn\n",
    "    # model_sk = KerasClassifier(build_fn=lambda: model, epochs=20, batch_size=32, verbose=0)\n",
    "    # scores = cross_val_score(model_sk, X, y, cv=5, scoring='accuracy')\n",
    "    # print(f\"Precisão média da validação cruzada: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Rede Neural Densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6327 - loss: 0.6868 - val_accuracy: 0.6349 - val_loss: 0.6656 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.6696 - val_accuracy: 0.6349 - val_loss: 0.6572 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 0.6634 - val_accuracy: 0.6349 - val_loss: 0.6565 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 0.6702 - val_accuracy: 0.6349 - val_loss: 0.6545 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6357 - loss: 0.6541 - val_accuracy: 0.6349 - val_loss: 0.6529 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6149 - loss: 0.6613 - val_accuracy: 0.6349 - val_loss: 0.6495 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6326 - loss: 0.6494 - val_accuracy: 0.6349 - val_loss: 0.6454 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6280 - loss: 0.6462 - val_accuracy: 0.6349 - val_loss: 0.6360 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6070 - loss: 0.6446 - val_accuracy: 0.6349 - val_loss: 0.6174 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6390 - loss: 0.6045 - val_accuracy: 0.6667 - val_loss: 0.6017 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6426 - loss: 0.5808 - val_accuracy: 0.6561 - val_loss: 0.5815 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.5589 - val_accuracy: 0.6720 - val_loss: 0.5627 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6889 - loss: 0.5700 - val_accuracy: 0.6667 - val_loss: 0.5728 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.5667 - val_accuracy: 0.6455 - val_loss: 0.5909 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6886 - loss: 0.5717 - val_accuracy: 0.6614 - val_loss: 0.5575 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7034 - loss: 0.5461 - val_accuracy: 0.6561 - val_loss: 0.5534 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6882 - loss: 0.5452 - val_accuracy: 0.6614 - val_loss: 0.5526 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6894 - loss: 0.5469 - val_accuracy: 0.6772 - val_loss: 0.5504 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.5247 - val_accuracy: 0.6614 - val_loss: 0.5518 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7117 - loss: 0.5164 - val_accuracy: 0.6667 - val_loss: 0.5584 - learning_rate: 0.0010\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Matriz de Confusão:\n",
      "[[53 16]\n",
      " [47 73]]\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step\n",
      "Precisão: 0.7143\n",
      "Recall: 0.6667\n",
      "F1-Score: 0.6725\n",
      "AUC: 0.7426\n"
     ]
    }
   ],
   "source": [
    "def test_dense_nn():\n",
    "    model = build_dense_nn((X_train.shape[1],))\n",
    "    avaliacoes(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "test_dense_nn()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens processadas: 941\n",
      "Dimensões de X_train: (752, 460, 700, 3)\n",
      "Dimensões de X_test: (189, 460, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_data_cnn(dataset_path, magnification, img_size, regex_label):\n",
    "    X = []\n",
    "    y = []\n",
    "    num_files = 0\n",
    "\n",
    "    # Percorrer o diretório de imagens\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        if os.path.basename(root) == magnification:\n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    img = cv2.imread(img_path)\n",
    "\n",
    "                    if img is None:\n",
    "                        print(f\"Erro ao carregar imagem: {file}\")\n",
    "                        continue\n",
    "\n",
    "                    # Redimensionar a imagem\n",
    "                    img = cv2.resize(img, img_size)\n",
    "                    X.append(img)\n",
    "\n",
    "                    # Extrair rótulo usando expressão regular\n",
    "                    match_obj = re.search(regex_label, file)\n",
    "                    if match_obj:\n",
    "                        label = match_obj.group(1)\n",
    "                        y.append(True if label == \"M\" else False)\n",
    "                    else:\n",
    "                        print(f\"Erro ao extrair rótulo da imagem: {file}\")\n",
    "\n",
    "                    num_files += 1\n",
    "\n",
    "    print(f\"Total de imagens processadas: {num_files}\")\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Exemplo de uso\n",
    "dataset_path = 'histology_slides'\n",
    "magnification = '200X'\n",
    "img_size = (700, 460)\n",
    "regex_label = r'_(M|B)_'\n",
    "\n",
    "X_cnn, y_cnn = load_data_cnn(dataset_path, magnification, img_size, regex_label)\n",
    "\n",
    "# Divida os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cnn, y_cnn, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verifique as dimensões de X_train e X_test\n",
    "print(f\"Dimensões de X_train: {X_train.shape}\")\n",
    "print(f\"Dimensões de X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Rede Neural Convolucional Básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.5423 - loss: 3445.4185 - val_accuracy: 0.7725 - val_loss: 4.2169 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.7842 - loss: 4.9511 - val_accuracy: 0.7302 - val_loss: 0.5652 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8244 - loss: 0.5565 - val_accuracy: 0.7460 - val_loss: 0.8236 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.8417 - loss: 0.5311 - val_accuracy: 0.7090 - val_loss: 0.6529 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.8636 - loss: 0.4110 - val_accuracy: 0.7778 - val_loss: 0.6063 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.8356 - loss: 0.4927 - val_accuracy: 0.7672 - val_loss: 0.6178 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.8877 - loss: 0.3906 - val_accuracy: 0.7989 - val_loss: 0.5848 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9014 - loss: 0.3696 - val_accuracy: 0.8095 - val_loss: 0.5925 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9261 - loss: 0.3280 - val_accuracy: 0.8095 - val_loss: 0.5947 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9191 - loss: 0.3635 - val_accuracy: 0.8095 - val_loss: 0.5979 - learning_rate: 1.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9217 - loss: 0.3536 - val_accuracy: 0.8095 - val_loss: 0.5994 - learning_rate: 1.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9365 - loss: 0.3184 - val_accuracy: 0.7937 - val_loss: 0.6061 - learning_rate: 1.0000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9427 - loss: 0.2953 - val_accuracy: 0.7989 - val_loss: 0.6109 - learning_rate: 1.0000e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9240 - loss: 0.3087 - val_accuracy: 0.7884 - val_loss: 0.6163 - learning_rate: 1.0000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9298 - loss: 0.3308 - val_accuracy: 0.7937 - val_loss: 0.6230 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9269 - loss: 0.3426 - val_accuracy: 0.8095 - val_loss: 0.6152 - learning_rate: 1.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9381 - loss: 0.3226 - val_accuracy: 0.8042 - val_loss: 0.6169 - learning_rate: 1.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.9394 - loss: 0.2938 - val_accuracy: 0.8042 - val_loss: 0.6191 - learning_rate: 1.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.9418 - loss: 0.3145 - val_accuracy: 0.8095 - val_loss: 0.6221 - learning_rate: 1.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.9540 - loss: 0.2811 - val_accuracy: 0.8148 - val_loss: 0.6254 - learning_rate: 1.0000e-05\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 431ms/step\n",
      "Matriz de Confusão:\n",
      "[[55 12]\n",
      " [23 99]]\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 429ms/step\n",
      "Precisão: 0.8257\n",
      "Recall: 0.8148\n",
      "F1-Score: 0.8175\n",
      "AUC: 0.8503\n"
     ]
    }
   ],
   "source": [
    "def test_basic_cnn():\n",
    "    model = build_basic_cnn((img_size[0], img_size[1], 3))\n",
    "    avaliacoes(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "test_basic_cnn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
